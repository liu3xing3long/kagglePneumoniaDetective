{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "# links\n",
    "[Kaggle Challenge - Getting Started](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge#Getting%20Started) <br>\n",
    "[md ai GitHub](https://github.com/mdai/ml-lessons) <br>\n",
    "[md ai My projects](https://public.md.ai/hub/projects/user) <br>\n",
    "[Google Colab kaggle](https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson3-rsna-pneumonia-detection-kaggle.ipynb) <br>\n",
    "[darknet](https://github.com/pjreddie/darknet) <br>\n",
    "[darknet train classifier from scratch](https://pjreddie.com/darknet/train-cifar/) <br>\n",
    "****\n",
    "## DarkNet, You Only Look Once YOLO & python wrappers\n",
    "\n",
    "[YOLO](https://pjreddie.com/darknet/yolo/) <br>\n",
    "[YOLO - python](https://github.com/madhawav/YOLO3-4-Py) <br>\n",
    "[YOLO - py - docker](https://github.com/madhawav/YOLO3-4-Py/tree/master/docker) <br>\n",
    "[darknetpy pypi](https://pypi.org/project/darknetpy/) <br>\n",
    "[darknetpy GitHub](https://github.com/danielgatis/darknetpy) <br>\n",
    "[lightnet GitHub](https://github.com/explosion/lightnet) <br>\n",
    "****\n",
    "## DarkNet Training Example:\n",
    "[darknet train from scratch](https://pjreddie.com/darknet/train-cifar/) <br>\n",
    "```bash\n",
    "# cfar.data:\n",
    "classes=10\n",
    "train  = data/cifar/train.list\n",
    "valid  = data/cifar/test.list\n",
    "labels = data/cifar/labels.txt\n",
    "backup = backup/\n",
    "top=2\n",
    "```\n",
    "    * files:\n",
    "        * cfg/cfar.data == location of backup dir and labels, train and test data list files.\n",
    "        * cfg/cifar_small.cfg == the configuration of the network (in full detail)\n",
    "    * get the training list and the test list in files\n",
    "****\n",
    "```bash\n",
    "cd cifar\n",
    "find `pwd`/train -name \\*.png > train.list\n",
    "find `pwd`/test -name \\*.png > test.list\n",
    "cd ../..\n",
    "```\n",
    "****\n",
    "    * Train the network (or restart training)\n",
    "```bash\n",
    "../../darknet/darknet classifier train cfg/kaggle.data cfg/kaggle.cfg\n",
    "# ../../darknet/darknet classifier train cfg/kaggle.data cfg/kaggle.cfg ../data/backup/kaggle_x.weights\n",
    "# Use last completed number  x id. est. kaggle_7.weights\n",
    "```\n",
    "****\n",
    "    * Validate the model\n",
    "```bash\n",
    "darknet classifier valid cfg/cifar.data cfg/cifar_small.cfg backup/cifar_small.backup\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from shutil import copyfile\n",
    "import glob\n",
    "\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# '../../src/dcm_wrangler.py'\n",
    "sys.path.insert(1, '../src/')\n",
    "import kaggle_wrangler as kgwr\n",
    "\n",
    "kaggle_data_dir = '../data/all'\n",
    "train_data_dir = os.path.join(kaggle_data_dir, 'stage_1_train_images')\n",
    "test_data_dir = os.path.join(kaggle_data_dir, 'stage_1_test_images')\n",
    "preprocessed_images_dir = '../data/train_data_selected'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample a training and test set from the resized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   total number of files:     30980\n",
      "                         train set files:     27882\n",
      "                          test set files:      3098\n",
      "\n",
      "                                    type:      size\n",
      "                          <class 'list'>:     27882\n",
      "                          <class 'list'>:      3098\n"
     ]
    }
   ],
   "source": [
    "#                                    Define - designate\n",
    "test_set_fraction = 0.1\n",
    "config_dir = 'cfg'\n",
    "train_data_dir = '../data/kaggle_train'\n",
    "test_data_dir = '../data/kaggle_test'\n",
    "\n",
    "#                                    Locate\n",
    "all_files_list = os.listdir(preprocessed_images_dir)\n",
    "\n",
    "number_of_samples = len(all_files_list)\n",
    "test_set_size = int(number_of_samples * test_set_fraction)\n",
    "train_set_size = number_of_samples - test_set_size\n",
    "print('%40s: %9i'%('total number of files', number_of_samples))\n",
    "print('%40s: %9i'%('train set files', train_set_size))\n",
    "print('%40s: %9i'%('test set files', test_set_size))\n",
    "\n",
    "#                                    Sample\n",
    "train_set = random.sample(all_files_list, train_set_size)\n",
    "test_set = list(set(all_files_list) - set(train_set))\n",
    "print('\\n%40s: %9s'%('type', 'size'))\n",
    "print('%40s: %9i'%(type(train_set), len(train_set)))\n",
    "print('%40s: %9i'%(type(test_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg/train.list written from 27882 items in train_files_list\n",
      "cfg/test.list written from 3098 items in test_files_list\n"
     ]
    }
   ],
   "source": [
    "#                                    Move train set\n",
    "train_files_name = os.path.join(config_dir, 'train.list')\n",
    "test_files_name = os.path.join(config_dir, 'test.list')\n",
    "\n",
    "train_files_list = []\n",
    "test_files_list = []\n",
    "\n",
    "for train_file in train_set:\n",
    "    src_file_name = os.path.join(preprocessed_images_dir, train_file)\n",
    "    dest_file_name = os.path.join(train_data_dir, train_file)\n",
    "    copyfile(src_file_name, dest_file_name)\n",
    "    train_files_list.append(dest_file_name)\n",
    "\n",
    "\n",
    "with open(train_files_name, 'w') as f:\n",
    "    for item in train_files_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "    print(train_files_name, 'written from %i'%(len(train_files_list)), 'items in train_files_list' )\n",
    "\n",
    "\n",
    "#                                    Move test set\n",
    "for test_file in test_set:\n",
    "    src_file_name = os.path.join(preprocessed_images_dir, test_file)\n",
    "    dest_file_name = os.path.join(test_data_dir, test_file)\n",
    "    copyfile(src_file_name, dest_file_name)\n",
    "    test_files_list.append(dest_file_name)\n",
    "\n",
    "with open(test_files_name, 'w') as f:\n",
    "    for item in test_files_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "    print(test_files_name, 'written from %i'%(len(test_files_list)), 'items in test_files_list' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the config files and train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile('../../darknet/darknet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cfg/labels.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile cfg/labels.txt\n",
    "Normal_Negative\n",
    "NoLuOpNotNorm_Negative\n",
    "LuOp_Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cfg/kaggle.data\n"
     ]
    }
   ],
   "source": [
    "%%writefile cfg/kaggle.data\n",
    "classes=3\n",
    "train  = cfg/train.list\n",
    "valid  = cfg/test.list\n",
    "labels = cfg/labels.txt\n",
    "backup = ../data/backup/\n",
    "top=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "# initial start:\n",
    "../../darknet/darknet classifier train cfg/kaggle.data cfg/kaggle.cfg\n",
    "\n",
    "# for a restart:\n",
    "../../darknet/darknet classifier train cfg/kaggle.data cfg/kaggle.cfg ../data/backup/kaggle_x.weights\n",
    "```\n",
    "#### modified config files for kaggle data (grayscale):\n",
    "    * cfg/kaggle.data\n",
    "        * classes = 3                # (instead of 10)\n",
    "        * backup  = ../data/backup/  # (after creating backup dir)\n",
    "    * cfg/kaggle.cfg  removed:\n",
    "        * hue=.1\n",
    "        * saturation=.75\n",
    "        * exposure=.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "[net]\n",
    "batch=128\n",
    "subdivisions=1\n",
    "height=28\n",
    "width=28\n",
    "channels=1\n",
    "max_crop=32\n",
    "min_crop=32\n",
    "\n",
    "learning_rate=0.1\n",
    "policy=poly\n",
    "power=4\n",
    "max_batches = 5000\n",
    "momentum=0.9\n",
    "decay=0.0005\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cfg/kaggle.cfg\n"
     ]
    }
   ],
   "source": [
    "%%writefile cfg/kaggle.cfg\n",
    "[net]\n",
    "batch=128\n",
    "subdivisions=1\n",
    "height=28\n",
    "width=28\n",
    "channels=3\n",
    "max_crop=32\n",
    "min_crop=32\n",
    "\n",
    "learning_rate=0.1\n",
    "policy=poly\n",
    "power=4\n",
    "max_batches = 5000\n",
    "momentum=0.9\n",
    "decay=0.0005\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=2\n",
    "\n",
    "[dropout]\n",
    "probability=.5\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=2\n",
    "\n",
    "[dropout]\n",
    "probability=.5\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[dropout]\n",
    "probability=.5\n",
    "\n",
    "[convolutional]\n",
    "filters=3\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[avgpool]\n",
    "\n",
    "[softmax]\n",
    "groups=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pastable clde for writing labels file\n",
    "```python\n",
    "#                                       get the labels, write the labels file\n",
    "def get_underscore_labels(data_dir):\n",
    "    \"\"\" labels_list = get_underscore_labels(data_dir) \"\"\"\n",
    "    files_list = os.listdir(data_dir)\n",
    "    labels_list = []\n",
    "    for name in files_list:\n",
    "        s2 = name.split('.')[0].split('_')\n",
    "        new_name = s2[-2] + '_' + s2[-1]\n",
    "        if not new_name in labels_list:\n",
    "            labels_list.append(new_name)\n",
    "            \n",
    "    return labels_list\n",
    "    \n",
    "labels_list = get_underscore_labels(preprocessed_images_dir)\n",
    "for label in labels_list:\n",
    "    print(label)\n",
    "    \n",
    "config_dir = 'cfg'\n",
    "labels_file_name = os.path.join(config_dir, 'labels.txt')\n",
    "if os.path.isdir(config_dir) and not os.path.isfile(labels_file_name):\n",
    "    with open(labels_file_name, 'w') as f:\n",
    "        for item in labels_list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "else:\n",
    "    print('Not writing:', labels_file_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
