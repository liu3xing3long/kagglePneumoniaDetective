{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle RSNA Pneumonia Detection Challenge:\n",
    "   ### Build an algorithm that automatically detects potential pneumonia cases (from images).\n",
    "   ### Evaluated at different thresholds for intersection over union of bounding boxes (or objects).\n",
    "\\begin{align}\n",
    "\\ \\mbox{IoU(A, B) intersection over union} \\\\\n",
    "\\ \\mbox{A predicted bounding boxes} \\\\\n",
    "\\ \\mbox{B ground truth bounding boxes} \\\\\n",
    "\\ IoU(A, B) = \\frac{A \\bigcap B}{A \\bigcup B} \\\\ \n",
    "\\ \\\\\n",
    "\\ \\textit{At each threshold value t} \\\\\n",
    "\\ IoU(A, B) = \\frac{TP(t)}{TP(t)+FP(t)+FN(t)} \\\\\n",
    "\\ \\\\\n",
    "\\ \\textit{True Positives TP} \\\\\n",
    "\\ \\textit{False Positives FP} \\\\\n",
    "\\ \\textit{False Negatives FP} \\\\\n",
    "\\ \\textit{for threshold step of 0.5 over (0.4, 0.75)} \\\\\n",
    "\\ \\\\\n",
    "\\ \\textit{else the precision of a single image is:} \\\\\n",
    "\\ \\frac{1}{|thresholds|} \\sum_t \\frac{TP(t)}{TP(t)+FP(t)+FN(t)} \\\\\n",
    "\\end{align}\n",
    "\n",
    "    * Note that if ground truth is None, any False Positives give the image a score of 0\n",
    "    * In nearly all cases confidence will have no effect on scoring\n",
    "    \n",
    "****\n",
    "\n",
    "# links\n",
    "[Kaggle Challenge - Getting Started](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge#Getting%20Started) <br>\n",
    "[md ai GitHub](https://github.com/mdai/ml-lessons) <br>\n",
    "[md ai My projects](https://public.md.ai/hub/projects/user) <br>\n",
    "[Google Colab kaggle](https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson3-rsna-pneumonia-detection-kaggle.ipynb) <br>\n",
    "[darknet](https://github.com/pjreddie/darknet) <br>\n",
    "[darknet train classifier from scratch](https://pjreddie.com/darknet/train-cifar/) <br>\n",
    "\n",
    "## DarkNet, You Only Look Once YOLO & python wrappers\n",
    "****\n",
    "[YOLO](https://pjreddie.com/darknet/yolo/) <br>\n",
    "[YOLO - python](https://github.com/madhawav/YOLO3-4-Py) <br>\n",
    "[YOLO - py - docker](https://github.com/madhawav/YOLO3-4-Py/tree/master/docker) <br>\n",
    "[darknetpy pypi](https://pypi.org/project/darknetpy/) <br>\n",
    "[darknetpy GitHub](https://github.com/danielgatis/darknetpy) <br>\n",
    "[lightnet GitHub](https://github.com/explosion/lightnet) <br>\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import glob\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# '../../src/dcm_wrangler.py'\n",
    "sys.path.insert(1, '../src/')\n",
    "import kaggle_wrangler as kgwr\n",
    "\n",
    "kaggle_data_dir = '../data/all'\n",
    "train_data_dir = os.path.join(kaggle_data_dir, 'stage_1_train_images')\n",
    "test_data_dir = os.path.join(kaggle_data_dir, 'stage_1_test_images')\n",
    "\n",
    "# os.listdir(kaggle_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## following directions:\n",
    "[exploratory data analysis](https://www.kaggle.com/peterchang77/exploratory-data-analysis) <br>\n",
    "\n",
    "## extracting the boxed parts or lungs into thumbnails\n",
    "    * 1) Get the list of training labels dataframe and the detailed class info dataframe.\n",
    "    * 2) For each patientId construct a image file name for each box with these parts:\n",
    "        * patientId\n",
    "        * box number if one or more box\n",
    "        * class code\n",
    "    * 3) Save the boxed image for each box or lung if no boxes\n",
    "        * arbitrarily select the left and right lung.\n",
    "        * exactly select each box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution they have duplicate patient id's\n",
    "\n",
    "labels_df = pd.read_csv(os.path.join(kaggle_data_dir, 'stage_1_train_labels.csv'))\n",
    "class_df = pd.read_csv(os.path.join(kaggle_data_dir, 'stage_1_detailed_class_info.csv'))\n",
    "# dfinal = labels_df.merge(class_df, on=\"patientId\", how='inner')\n",
    "\n",
    "parsed = kgwr.parse_data(labels_df, train_data_dir)\n",
    "pt_Id_list = sorted(list(parsed.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "out_dir_local = os.path.abspath('../data/train_data_select')\n",
    "all_files_written_list = []\n",
    "\n",
    "with_pneumonia = 0\n",
    "without_pneumonia = 0\n",
    "class_conflicted = 0\n",
    "conflicted_Positive_patientID_list = []\n",
    "conflicted_Negative_patientID_list = []\n",
    "count = 0\n",
    "max_count = 100000\n",
    "for patientID in pt_Id_list:\n",
    "    count += 1\n",
    "    Target_rows = labels_df[labels_df['patientId'] == patientID]\n",
    "    if any(Target_rows['Target'] == 0):\n",
    "        without_pneumonia += 1\n",
    "        written_files_list = kgwr.write_negative_test_images(patientID, parsed, class_df, out_dir=out_dir_local)\n",
    "        if len(written_files_list) > 0:\n",
    "            for written in written_files_list:\n",
    "                all_files_written_list.append(written)\n",
    "        else:\n",
    "            conflicted_Positive_patientID_list.append(patientID)\n",
    "            class_conflicted += 1\n",
    "        \n",
    "    elif any(Target_rows['Target'] == 1):\n",
    "        with_pneumonia += 1\n",
    "        written_files_list = kgwr.write_box_images(patientID, parsed, class_df, out_dir=out_dir_local)\n",
    "        if len(written_files_list) > 0:\n",
    "            for written in written_files_list:\n",
    "                all_files_written_list.append(written)\n",
    "        else:\n",
    "            conflicted_Negative_patientID_list.append(patientID)\n",
    "            class_conflicted += 1\n",
    "    else:\n",
    "        class_conflicted += 1\n",
    "        \n",
    "    if count > max_count:\n",
    "        break\n",
    "        \n",
    "    if np.mod(count, 1000) == 0:\n",
    "        print('count', count)\n",
    "        \n",
    "print('Total files written',len(all_files_written_list))\n",
    "print('In total time %0.3f'%(time.time() - t0))\n",
    "\n",
    "print('\\nwith_pneumonia', with_pneumonia, \n",
    "      '\\nwithout_pneumonia', without_pneumonia, \n",
    "      '\\nclass_conflicted', class_conflicted)\n",
    "\n",
    "print('writing Conflicted PatientID lists')\n",
    "\n",
    "with open('conflicted_Negatives.txt', 'w') as f:\n",
    "    for item in conflicted_Negative_patientID_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open('conflicted_Positives.txt', 'w') as f:\n",
    "    for item in conflicted_Positive_patientID_list:\n",
    "        f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "Total files written 30980\n",
    "In total time 1671.489\n",
    "\n",
    "with_pneumonia 5659 \n",
    "without_pneumonia 20025 \n",
    "class_conflicted 9458\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30980"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files_written = os.listdir('../data/train_data_selected')\n",
    "len(all_files_written)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(20):\n",
    "    patientID = pt_Id_list[n]\n",
    "    Target_rows = labels_df[labels_df['patientId'] == patientID]\n",
    "    if any(Target_rows['Target'] == 0):\n",
    "        if os.path.isfile(parsed[patientID]['dicom']):\n",
    "            print('number',n, '\\t\\tpatientID:', patientID)\n",
    "            pylab.figure()\n",
    "            kgwr.draw(parsed[patientID])\n",
    "        else:\n",
    "            print('file Not found')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patientID)\n",
    "written_files_list = kgwr.write_box_images(patientID, parsed, class_df, out_dir=None)\n",
    "for full_file in written_files_list:\n",
    "    wrt_dir, f_name = os.path.split(full_file)\n",
    "    print(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import time\n",
    "t0 = time.time()\n",
    "out_dir_local = os.path.abspath('train_data')\n",
    "all_files_written_list = []\n",
    "for patientID in pt_Id_list:\n",
    "    written_files_list = kgwr.write_box_images(patientID, parsed, class_df, out_dir=out_dir_local)\n",
    "    if len(written_files_list) > 0:\n",
    "        for written in written_files_list:\n",
    "            all_files_written_list.append(written)\n",
    "    else:\n",
    "print(len(all_files_written_list))\n",
    "print('tt', time.time() - t0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/kaggle_wrangler.py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "file_ext = '.png'\n",
    "class_codes_dict = {'No Lung Opacity / Not Normal': 'NoLuOpNotNorm',\n",
    "                            'Lung Opacity': 'LuOp',\n",
    "                                  'Normal': 'Normal'}\n",
    "\n",
    "def write_negative_test_images(patientID, parsedict, class_df, out_dir=None):\n",
    "    \"\"\" written_files_list = write_negative_test_images(patientID, parsedict, class_df, out_dir=None) \n",
    "    Note that file name L and R is patient point of view whereas variable names are X-ray point of view\n",
    "    \"\"\"\n",
    "    if out_dir is None: out_dir = os.getcwd()\n",
    "        \n",
    "    # arbitrary cropping boxes\n",
    "    row_crop = np.array([0.2, 0.7])\n",
    "    col_crop = np.array([0.23, 0.46, 0.54, 0.77])\n",
    "    \n",
    "    written_files_list = []\n",
    "    class_code = get_class_code(patientID, class_df) + '_Negative'\n",
    "    dcm_file_name = parsedict[patientID]['dicom']\n",
    "    if os.path.isfile(dcm_file_name):\n",
    "        dcm_data = pydicom.read_file(dcm_file_name)\n",
    "        im = dcm_data.pixel_array\n",
    "        im_size = im.shape\n",
    "        row_bounds = np.int_(row_crop * im_size[0])\n",
    "        col_bounds = np.int_(col_crop * im_size[1])\n",
    "\n",
    "        left_im = im[row_bounds[0]:row_bounds[1], col_bounds[0]:col_bounds[1]]\n",
    "        left_im = Image.fromarray(left_im)\n",
    "        left_box_file_name = patientID + '_R_' + class_code + file_ext\n",
    "        left_box_full_file_name = os.path.join(out_dir, left_box_file_name)\n",
    "        left_im.save(left_box_full_file_name, 'png')\n",
    "        written_files_list.append(left_box_file_name)\n",
    "\n",
    "        right_im = im[row_bounds[0]:row_bounds[1], col_bounds[2]:col_bounds[3]]\n",
    "        right_im = Image.fromarray(right_im)\n",
    "        right_box_file_name = patientID + '_L_' + class_code + file_ext\n",
    "        right_box_full_file_name = os.path.join(out_dir, right_box_file_name)\n",
    "        right_im.save(right_box_full_file_name, 'png')\n",
    "        written_files_list.append(right_box_file_name)\n",
    "    \n",
    "    return written_files_list\n",
    "\n",
    "def write_box_images(patientID, parsedict, class_df, out_dir=None):\n",
    "    \"\"\" written_files_list = write_box_images(patientID, parsedict, class_df, out_dir=None) \n",
    "    \"\"\"\n",
    "    if out_dir is None: out_dir = os.getcwd()\n",
    "    written_files_list = []\n",
    "    boxes_dict = get_boxes(patientID, parsedict)\n",
    "    if boxes_dict['number_of_boxes'] > 0:\n",
    "        class_code = get_class_code(patientID, class_df) + '_Positive'\n",
    "        dcm_file_name = parsedict[patientID]['dicom']\n",
    "        if os.path.isfile(dcm_file_name):\n",
    "            dcm_data = pydicom.read_file(dcm_file_name)\n",
    "            im = dcm_data.pixel_array\n",
    "            for box_number in range(boxes_dict['number_of_boxes']):\n",
    "                box_file_name = get_thumbnail_name(patientID, class_code, box_number)\n",
    "                box_file_full_name = os.path.join(out_dir, box_file_name)\n",
    "                box = boxes_dict[box_number]\n",
    "                box_im = im[box[0]: box[0]+box[2],box[1]: box[1]+box[3]]\n",
    "                Box_Image = Image.fromarray(box_im)\n",
    "                Box_Image.save(box_file_full_name, \"png\")\n",
    "                written_files_list.append(box_file_name)\n",
    "            \n",
    "    return written_files_list\n",
    "\n",
    "def get_thumbnail_name(patientID, class_code, box_number):\n",
    "    thumbnail_name = patientID + '_%i_'%(box_number) + class_code + file_ext\n",
    "    return thumbnail_name\n",
    "\n",
    "def get_class_code(patientID, class_info_df):\n",
    "    index_list = class_info_df.index[class_info_df['patientId'] == patientID].tolist()\n",
    "    class_code_key = class_info_df.loc[index_list[0]]['class']\n",
    "    return class_codes_dict[class_code_key]\n",
    "\n",
    "def get_boxes(patientID, parsed_data):\n",
    "    boxes_list = parsed_data[patientID]['boxes']\n",
    "    boxes_dict = {'number_of_boxes':len(boxes_list)}\n",
    "    if boxes_dict['number_of_boxes'] > 0:\n",
    "        box_number = 0\n",
    "        for box in boxes_list:\n",
    "            boxes_dict[box_number] = np.int_(np.array(boxes_list[box_number]))\n",
    "            box_number += 1\n",
    "        \n",
    "    return boxes_dict\n",
    "\n",
    "# https://www.kaggle.com/peterchang77/exploratory-data-analysis\n",
    "\n",
    "def parse_data(df, images_dir):\n",
    "    \"\"\"\n",
    "    Method to read a CSV file (Pandas dataframe) and parse the \n",
    "    data into the following nested dictionary:\n",
    "      parsed = {\n",
    "        'patientId-00': {\n",
    "            'dicom': path/to/dicom/file,\n",
    "            'label': either 0 or 1 for normal or pnuemonia, \n",
    "            'boxes': list of box(es)\n",
    "        },\n",
    "        'patientId-01': {\n",
    "            'dicom': path/to/dicom/file,\n",
    "            'label': either 0 or 1 for normal or pnuemonia, \n",
    "            'boxes': list of box(es)\n",
    "        }, ...\n",
    "      }\n",
    "    \"\"\"\n",
    "    # --- Define lambda to extract coords in list [y, x, height, width]\n",
    "    extract_box = lambda row: [row['y'], row['x'], row['height'], row['width']]\n",
    "\n",
    "    parsed = {}\n",
    "    for n, row in df.iterrows():\n",
    "        # --- Initialize patient entry into parsed \n",
    "        pid = row['patientId']\n",
    "        if pid not in parsed:\n",
    "            parsed[pid] = {\n",
    "                'dicom': os.path.join(images_dir, '%s.dcm'% pid),\n",
    "                'label': row['Target'],\n",
    "                'boxes': []}\n",
    "        # --- Add box if opacity is present\n",
    "        if parsed[pid]['label'] == 1:\n",
    "            parsed[pid]['boxes'].append(extract_box(row))\n",
    "\n",
    "    return parsed\n",
    "\n",
    "def draw(data):\n",
    "    \"\"\" Method to draw single patient with bounding box(es) if present \"\"\"\n",
    "    # --- Open DICOM file\n",
    "    d = pydicom.read_file(data['dicom'])\n",
    "    im = d.pixel_array\n",
    "\n",
    "    # --- Convert from single-channel grayscale to 3-channel RGB\n",
    "    im = np.stack([im] * 3, axis=2)\n",
    "\n",
    "    # --- Add boxes with random color if present\n",
    "    for box in data['boxes']:\n",
    "        rgb = np.floor(np.random.rand(3) * 256).astype('int')\n",
    "        im = overlay_box(im=im, box=box, rgb=rgb, stroke=6)\n",
    "\n",
    "    pylab.imshow(im, cmap=pylab.cm.gist_gray)\n",
    "    pylab.axis('off')\n",
    "\n",
    "def overlay_box(im, box, rgb, stroke=1):\n",
    "    \"\"\" Method to overlay single box on image \"\"\"\n",
    "    # --- Convert coordinates to integers\n",
    "    box = [int(b) for b in box]\n",
    "    \n",
    "    # --- Extract coordinates\n",
    "    y1, x1, height, width = box\n",
    "    y2 = y1 + height\n",
    "    x2 = x1 + width\n",
    "\n",
    "    im[y1:y1 + stroke, x1:x2] = rgb\n",
    "    im[y2:y2 + stroke, x1:x2] = rgb\n",
    "    im[y1:y2, x1:x1 + stroke] = rgb\n",
    "    im[y1:y2, x2:x2 + stroke] = rgb\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
